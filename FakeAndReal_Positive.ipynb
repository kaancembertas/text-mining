{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kaan-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kaan-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>I was completely blown away by this hotel. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>We've just returned from a two night stay at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>Excellent location, feels like a boutique hote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>I travel a lot for business and quite frankly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>We visited for my 40th birthday. We had never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>fake_positive</td>\n",
       "      <td>The rates at The Talbott Hotel were cheaper th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>fake_positive</td>\n",
       "      <td>I enjoyed my stay at the Talbott Hotel. It is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>fake_positive</td>\n",
       "      <td>Pleasant staff and housekeeping. Above average...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>fake_positive</td>\n",
       "      <td>My stay at this hotel was one of the best I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>fake_positive</td>\n",
       "      <td>excellent staff and customer service, very cle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              type                                               text\n",
       "0    real_positive  I was completely blown away by this hotel. It ...\n",
       "1    real_positive  We've just returned from a two night stay at t...\n",
       "2    real_positive  Excellent location, feels like a boutique hote...\n",
       "3    real_positive  I travel a lot for business and quite frankly,...\n",
       "4    real_positive  We visited for my 40th birthday. We had never ...\n",
       "..             ...                                                ...\n",
       "395  fake_positive  The rates at The Talbott Hotel were cheaper th...\n",
       "396  fake_positive  I enjoyed my stay at the Talbott Hotel. It is ...\n",
       "397  fake_positive  Pleasant staff and housekeeping. Above average...\n",
       "398  fake_positive  My stay at this hotel was one of the best I ha...\n",
       "399  fake_positive  excellent staff and customer service, very cle...\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_documents(doc_type,path):\n",
    "    files = path.iterdir()\n",
    "    document_arr = []\n",
    "\n",
    "    for index,file in enumerate(files, start=0):\n",
    "        reader = open(file,\"r\")\n",
    "        text = reader.read()\n",
    "        document_arr.append({'type':doc_type,'text':text})\n",
    "    return document_arr\n",
    "\n",
    "real_positive_path = Path('opinion_spam/positive/truthful')\n",
    "fake_positive_path = Path('opinion_spam/positive/deceptive')\n",
    "\n",
    "docs = pd.DataFrame()\n",
    "docs = docs.append(read_documents('real_positive',real_positive_path))\n",
    "docs = docs.append(read_documents('fake_positive',fake_positive_path))\n",
    "len(docs)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords (text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    new_text = ' '.join([x for x in text.split() if x not in stop_words])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming (text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    new_text = ' '.join([stemmer.stem(x) for x in text.split()])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_by_filters (text,filters=[]):\n",
    "        new_text = ' '.join([x for x in text.split() if x not in filters])\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text (text):\n",
    "    # Lower text\n",
    "    new_text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    new_text = re.sub(r'\\d+', '', new_text) \n",
    "    \n",
    "    # Remove punctuations\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    new_text = new_text.translate(translator)\n",
    "    \n",
    "    # Remove white spaces\n",
    "    new_text = \" \".join(new_text.split())\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    new_text = remove_stopwords(new_text)\n",
    "    \n",
    "    # Stemming\n",
    "    new_text = apply_stemming(new_text)\n",
    "    \n",
    "    # Apply filter with words room,hotel,stay\n",
    "    new_text = remove_by_filters(new_text,['room','hotel','stay'])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['cleaned'] = docs['text'].apply(lambda text: preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      complet blown away magnific got great deal hap...\n",
       "1      weve return two night affinia chicago visit de...\n",
       "2      excel locat feel like boutiqu right next neima...\n",
       "3      travel lot busi quit frank expect start reach ...\n",
       "4      visit th birthday never chicago sure found dea...\n",
       "                             ...                        \n",
       "395    rate talbott cheaper expect reason book prepar...\n",
       "396    enjoy talbott expens side worth got talbott tr...\n",
       "397    pleasant staff housekeep averag breakfast clea...\n",
       "398    one best ever locat servic accommod outstand l...\n",
       "399    excel staff custom servic clean spotless eleg ...\n",
       "Name: cleaned, Length: 800, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification for All CLASSES\n",
    "### Naivebayes Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>street</th>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0.235063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corner</th>\n",
       "      <td>0.210892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>0.172386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolv</th>\n",
       "      <td>0.169364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fireplac</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firework</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firm</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4160 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tfidf\n",
       "street    0.275676\n",
       "state     0.235063\n",
       "corner    0.210892\n",
       "around    0.172386\n",
       "revolv    0.169364\n",
       "...            ...\n",
       "fire      0.000000\n",
       "fireplac  0.000000\n",
       "firework  0.000000\n",
       "firm      0.000000\n",
       "zoo       0.000000\n",
       "\n",
       "[4160 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "doc_vectors=tfidf_vectorizer.fit_transform(docs.cleaned)\n",
    "sample_tfidf_vector = doc_vectors[40]\n",
    "df = pd.DataFrame(sample_tfidf_vector.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = MultinomialNB().fit(doc_vectors, docs.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same operations with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pipeline,k):\n",
    "    # Divide the data; test&training\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(docs.cleaned,docs.type,test_size=0.2,random_state=0)\n",
    "    # Instead of use %20 of data as a test, I will use K-Cross Validation\n",
    "    kfold = KFold(n_splits=k,shuffle=True,random_state=0)\n",
    "    k_cross_splits = kfold.split(docs.cleaned,docs.type)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in k_cross_splits:\n",
    "        X = docs['cleaned']\n",
    "        X = np.array(X)\n",
    "        y = docs['type']\n",
    "        y = np.array(y)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        pipeline.fit(X_train,y_train)\n",
    "        predicted = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test,predicted)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "        print(\"Accuracy Score:\",accuracy)\n",
    "        print(\"Classification Report\\n\",classification_report(y_test,predicted))\n",
    "        print(\"Confusion Matrix\\n\",confusion_matrix(y_test,predicted))\n",
    "        print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"Average accuracy of 5-cross validation:\",np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Unigram NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.88125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.91      0.88      0.89        88\n",
      "real_positive       0.85      0.89      0.87        72\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.88      0.88      0.88       160\n",
      " weighted avg       0.88      0.88      0.88       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[77 11]\n",
      " [ 8 64]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.77      0.96      0.85        72\n",
      "real_positive       0.96      0.76      0.85        88\n",
      "\n",
      "     accuracy                           0.85       160\n",
      "    macro avg       0.86      0.86      0.85       160\n",
      " weighted avg       0.87      0.85      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[69  3]\n",
      " [21 67]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.89375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.88      0.93      0.90        83\n",
      "real_positive       0.92      0.86      0.89        77\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.90      0.89      0.89       160\n",
      " weighted avg       0.90      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[77  6]\n",
      " [11 66]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.88125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.85      0.94      0.89        83\n",
      "real_positive       0.93      0.82      0.87        77\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.89      0.88      0.88       160\n",
      " weighted avg       0.89      0.88      0.88       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[78  5]\n",
      " [14 63]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.76      1.00      0.86        74\n",
      "real_positive       1.00      0.72      0.84        86\n",
      "\n",
      "     accuracy                           0.85       160\n",
      "    macro avg       0.88      0.86      0.85       160\n",
      " weighted avg       0.89      0.85      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74  0]\n",
      " [24 62]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.8712500000000001\n"
     ]
    }
   ],
   "source": [
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Naivebayes | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.85625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.89      0.84      0.87        88\n",
      "real_positive       0.82      0.88      0.85        72\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.85      0.86      0.86       160\n",
      " weighted avg       0.86      0.86      0.86       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74 14]\n",
      " [ 9 63]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.76      0.99      0.86        72\n",
      "real_positive       0.98      0.74      0.84        88\n",
      "\n",
      "     accuracy                           0.85       160\n",
      "    macro avg       0.87      0.86      0.85       160\n",
      " weighted avg       0.88      0.85      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71  1]\n",
      " [23 65]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.88      0.90      0.89        83\n",
      "real_positive       0.89      0.87      0.88        77\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.89      0.89      0.89       160\n",
      " weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[75  8]\n",
      " [10 67]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.86875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.84      0.93      0.88        83\n",
      "real_positive       0.91      0.81      0.86        77\n",
      "\n",
      "     accuracy                           0.87       160\n",
      "    macro avg       0.87      0.87      0.87       160\n",
      " weighted avg       0.87      0.87      0.87       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[77  6]\n",
      " [15 62]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.74      0.99      0.85        74\n",
      "real_positive       0.98      0.71      0.82        86\n",
      "\n",
      "     accuracy                           0.84       160\n",
      "    macro avg       0.86      0.85      0.84       160\n",
      " weighted avg       0.87      0.84      0.84       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[73  1]\n",
      " [25 61]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.86\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "\n",
    "# Build the model\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Naivebayes | Unigram-Bigram-Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.85625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.89      0.84      0.87        88\n",
      "real_positive       0.82      0.88      0.85        72\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.85      0.86      0.86       160\n",
      " weighted avg       0.86      0.86      0.86       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74 14]\n",
      " [ 9 63]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.76      0.99      0.86        72\n",
      "real_positive       0.98      0.74      0.84        88\n",
      "\n",
      "     accuracy                           0.85       160\n",
      "    macro avg       0.87      0.86      0.85       160\n",
      " weighted avg       0.88      0.85      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71  1]\n",
      " [23 65]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.88125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.88      0.89      0.89        83\n",
      "real_positive       0.88      0.87      0.88        77\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.88      0.88      0.88       160\n",
      " weighted avg       0.88      0.88      0.88       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74  9]\n",
      " [10 67]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.86875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.84      0.93      0.88        83\n",
      "real_positive       0.91      0.81      0.86        77\n",
      "\n",
      "     accuracy                           0.87       160\n",
      "    macro avg       0.87      0.87      0.87       160\n",
      " weighted avg       0.87      0.87      0.87       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[77  6]\n",
      " [15 62]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.83125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.74      0.99      0.84        74\n",
      "real_positive       0.98      0.70      0.82        86\n",
      "\n",
      "     accuracy                           0.83       160\n",
      "    macro avg       0.86      0.84      0.83       160\n",
      " weighted avg       0.87      0.83      0.83       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[73  1]\n",
      " [26 60]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.8574999999999999\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Decision Tree with criteria Entropy | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.675\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.73      0.65      0.69        88\n",
      "real_positive       0.62      0.71      0.66        72\n",
      "\n",
      "     accuracy                           0.68       160\n",
      "    macro avg       0.68      0.68      0.67       160\n",
      " weighted avg       0.68      0.68      0.68       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[57 31]\n",
      " [21 51]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.68125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.63      0.69      0.66        72\n",
      "real_positive       0.73      0.67      0.70        88\n",
      "\n",
      "     accuracy                           0.68       160\n",
      "    macro avg       0.68      0.68      0.68       160\n",
      " weighted avg       0.69      0.68      0.68       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[50 22]\n",
      " [29 59]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.70625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.72      0.71      0.72        83\n",
      "real_positive       0.69      0.70      0.70        77\n",
      "\n",
      "     accuracy                           0.71       160\n",
      "    macro avg       0.71      0.71      0.71       160\n",
      " weighted avg       0.71      0.71      0.71       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[59 24]\n",
      " [23 54]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.66875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.69      0.65      0.67        83\n",
      "real_positive       0.65      0.69      0.67        77\n",
      "\n",
      "     accuracy                           0.67       160\n",
      "    macro avg       0.67      0.67      0.67       160\n",
      " weighted avg       0.67      0.67      0.67       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[54 29]\n",
      " [24 53]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.6625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.61      0.76      0.67        74\n",
      "real_positive       0.74      0.58      0.65        86\n",
      "\n",
      "     accuracy                           0.66       160\n",
      "    macro avg       0.67      0.67      0.66       160\n",
      " weighted avg       0.68      0.66      0.66       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[56 18]\n",
      " [36 50]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.6787500000000001\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', decision_tree_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Decision Tree with criteria Gini | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.74      0.66      0.70        88\n",
      "real_positive       0.63      0.72      0.68        72\n",
      "\n",
      "     accuracy                           0.69       160\n",
      "    macro avg       0.69      0.69      0.69       160\n",
      " weighted avg       0.69      0.69      0.69       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[58 30]\n",
      " [20 52]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.6875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.62      0.78      0.69        72\n",
      "real_positive       0.77      0.61      0.68        88\n",
      "\n",
      "     accuracy                           0.69       160\n",
      "    macro avg       0.70      0.70      0.69       160\n",
      " weighted avg       0.70      0.69      0.69       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[56 16]\n",
      " [34 54]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.75      0.75      0.75        83\n",
      "real_positive       0.73      0.73      0.73        77\n",
      "\n",
      "     accuracy                           0.74       160\n",
      "    macro avg       0.74      0.74      0.74       160\n",
      " weighted avg       0.74      0.74      0.74       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[62 21]\n",
      " [21 56]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.77      0.70      0.73        83\n",
      "real_positive       0.71      0.78      0.74        77\n",
      "\n",
      "     accuracy                           0.74       160\n",
      "    macro avg       0.74      0.74      0.74       160\n",
      " weighted avg       0.74      0.74      0.74       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[58 25]\n",
      " [17 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.70625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.67      0.72      0.69        74\n",
      "real_positive       0.74      0.70      0.72        86\n",
      "\n",
      "     accuracy                           0.71       160\n",
      "    macro avg       0.71      0.71      0.71       160\n",
      " weighted avg       0.71      0.71      0.71       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[53 21]\n",
      " [26 60]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.7112499999999999\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"gini\")\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', decision_tree_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with K-NN | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.77      0.81      0.79        88\n",
      "real_positive       0.75      0.71      0.73        72\n",
      "\n",
      "     accuracy                           0.76       160\n",
      "    macro avg       0.76      0.76      0.76       160\n",
      " weighted avg       0.76      0.76      0.76       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71 17]\n",
      " [21 51]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.62      0.86      0.72        72\n",
      "real_positive       0.83      0.57      0.68        88\n",
      "\n",
      "     accuracy                           0.70       160\n",
      "    macro avg       0.73      0.71      0.70       160\n",
      " weighted avg       0.74      0.70      0.70       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[62 10]\n",
      " [38 50]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.71      0.84      0.77        83\n",
      "real_positive       0.79      0.62      0.70        77\n",
      "\n",
      "     accuracy                           0.74       160\n",
      "    macro avg       0.75      0.73      0.73       160\n",
      " weighted avg       0.75      0.74      0.73       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[70 13]\n",
      " [29 48]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.75\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.70      0.90      0.79        83\n",
      "real_positive       0.85      0.58      0.69        77\n",
      "\n",
      "     accuracy                           0.75       160\n",
      "    macro avg       0.77      0.74      0.74       160\n",
      " weighted avg       0.77      0.75      0.74       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[75  8]\n",
      " [32 45]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.75625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.66      0.97      0.79        74\n",
      "real_positive       0.96      0.57      0.72        86\n",
      "\n",
      "     accuracy                           0.76       160\n",
      "    macro avg       0.81      0.77      0.75       160\n",
      " weighted avg       0.82      0.76      0.75       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[72  2]\n",
      " [37 49]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.7412500000000001\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "neigh_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', neigh_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with K-NN | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.74      0.81      0.77        88\n",
      "real_positive       0.73      0.65      0.69        72\n",
      "\n",
      "     accuracy                           0.74       160\n",
      "    macro avg       0.74      0.73      0.73       160\n",
      " weighted avg       0.74      0.74      0.74       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71 17]\n",
      " [25 47]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.63      0.86      0.73        72\n",
      "real_positive       0.84      0.59      0.69        88\n",
      "\n",
      "     accuracy                           0.71       160\n",
      "    macro avg       0.74      0.73      0.71       160\n",
      " weighted avg       0.75      0.71      0.71       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[62 10]\n",
      " [36 52]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.71875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.69      0.83      0.75        83\n",
      "real_positive       0.77      0.60      0.67        77\n",
      "\n",
      "     accuracy                           0.72       160\n",
      "    macro avg       0.73      0.71      0.71       160\n",
      " weighted avg       0.73      0.72      0.71       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[69 14]\n",
      " [31 46]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.73      0.86      0.79        83\n",
      "real_positive       0.81      0.66      0.73        77\n",
      "\n",
      "     accuracy                           0.76       160\n",
      "    macro avg       0.77      0.76      0.76       160\n",
      " weighted avg       0.77      0.76      0.76       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71 12]\n",
      " [26 51]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.78125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.70      0.93      0.80        74\n",
      "real_positive       0.92      0.65      0.76        86\n",
      "\n",
      "     accuracy                           0.78       160\n",
      "    macro avg       0.81      0.79      0.78       160\n",
      " weighted avg       0.82      0.78      0.78       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[69  5]\n",
      " [30 56]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.7425\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "neigh_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', neigh_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SVM | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.825\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.87      0.81      0.84        88\n",
      "real_positive       0.78      0.85      0.81        72\n",
      "\n",
      "     accuracy                           0.82       160\n",
      "    macro avg       0.82      0.83      0.82       160\n",
      " weighted avg       0.83      0.82      0.83       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71 17]\n",
      " [11 61]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.83      0.88      0.85        72\n",
      "real_positive       0.89      0.85      0.87        88\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.86      0.86      0.86       160\n",
      " weighted avg       0.86      0.86      0.86       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[63  9]\n",
      " [13 75]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.89      0.89      0.89        83\n",
      "real_positive       0.88      0.88      0.88        77\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.89      0.89      0.89       160\n",
      " weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74  9]\n",
      " [ 9 68]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.86      0.94      0.90        83\n",
      "real_positive       0.93      0.83      0.88        77\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.89      0.89      0.89       160\n",
      " weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[78  5]\n",
      " [13 64]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.85      0.89      0.87        74\n",
      "real_positive       0.90      0.86      0.88        86\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.87      0.88      0.87       160\n",
      " weighted avg       0.88      0.88      0.88       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[66  8]\n",
      " [12 74]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.8675\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "svm_classifier = svm.SVC()\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', svm_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SVM | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.86      0.84      0.85        88\n",
      "real_positive       0.81      0.83      0.82        72\n",
      "\n",
      "     accuracy                           0.84       160\n",
      "    macro avg       0.84      0.84      0.84       160\n",
      " weighted avg       0.84      0.84      0.84       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74 14]\n",
      " [12 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.86875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.82      0.90      0.86        72\n",
      "real_positive       0.91      0.84      0.88        88\n",
      "\n",
      "     accuracy                           0.87       160\n",
      "    macro avg       0.87      0.87      0.87       160\n",
      " weighted avg       0.87      0.87      0.87       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[65  7]\n",
      " [14 74]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.89      0.89      0.89        83\n",
      "real_positive       0.88      0.88      0.88        77\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.89      0.89      0.89       160\n",
      " weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74  9]\n",
      " [ 9 68]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.87      0.93      0.90        83\n",
      "real_positive       0.92      0.84      0.88        77\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.89      0.89      0.89       160\n",
      " weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[77  6]\n",
      " [12 65]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_positive       0.83      0.92      0.87        74\n",
      "real_positive       0.92      0.84      0.88        86\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.88      0.88      0.87       160\n",
      " weighted avg       0.88      0.88      0.88       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[68  6]\n",
      " [14 72]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.8712500000000001\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "svm_classifier = svm.SVC()\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', svm_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
