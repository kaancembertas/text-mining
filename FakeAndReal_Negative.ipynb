{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kaan-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kaan-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real_negative</td>\n",
       "      <td>We stayed 2 nights over spring break in what w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>real_negative</td>\n",
       "      <td>Stayed at the Fitzpatrick as a result of all o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>real_negative</td>\n",
       "      <td>We booked this hotel as a last minute vacation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real_negative</td>\n",
       "      <td>This hotel is a shambles-furniture literally f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>real_negative</td>\n",
       "      <td>The hotel itself was beautiful and wonderful s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>My husband and I were planning our 1st year we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>I recently stayed at The Talbott Hotel for 3 n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>I'd expect a \"luxury\" hotel to pay more attent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>I selected The Talbott for my recent family va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>The Talbott Hotel claims to be Chicago's Premi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              type                                               text\n",
       "0    real_negative  We stayed 2 nights over spring break in what w...\n",
       "1    real_negative  Stayed at the Fitzpatrick as a result of all o...\n",
       "2    real_negative  We booked this hotel as a last minute vacation...\n",
       "3    real_negative  This hotel is a shambles-furniture literally f...\n",
       "4    real_negative  The hotel itself was beautiful and wonderful s...\n",
       "..             ...                                                ...\n",
       "395  fake_negative  My husband and I were planning our 1st year we...\n",
       "396  fake_negative  I recently stayed at The Talbott Hotel for 3 n...\n",
       "397  fake_negative  I'd expect a \"luxury\" hotel to pay more attent...\n",
       "398  fake_negative  I selected The Talbott for my recent family va...\n",
       "399  fake_negative  The Talbott Hotel claims to be Chicago's Premi...\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_documents(doc_type,path):\n",
    "    files = path.iterdir()\n",
    "    document_arr = []\n",
    "\n",
    "    for index,file in enumerate(files, start=0):\n",
    "        reader = open(file,\"r\")\n",
    "        text = reader.read()\n",
    "        document_arr.append({'type':doc_type,'text':text})\n",
    "    return document_arr\n",
    "\n",
    "real_positive_path = Path('opinion_spam/positive/truthful')\n",
    "fake_positive_path = Path('opinion_spam/positive/deceptive')\n",
    "real_negative_path = Path('opinion_spam/negative/truthful')\n",
    "fake_negative_path = Path('opinion_spam/negative/deceptive')\n",
    "\n",
    "docs = pd.DataFrame()\n",
    "docs = docs.append(read_documents('real_negative',real_negative_path))\n",
    "docs = docs.append(read_documents('fake_negative',fake_negative_path))\n",
    "len(docs)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords (text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    new_text = ' '.join([x for x in text.split() if x not in stop_words])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming (text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    new_text = ' '.join([stemmer.stem(x) for x in text.split()])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_by_filters (text,filters=[]):\n",
    "        new_text = ' '.join([x for x in text.split() if x not in filters])\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text (text):\n",
    "    # Lower text\n",
    "    new_text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    new_text = re.sub(r'\\d+', '', new_text) \n",
    "    \n",
    "    # Remove punctuations\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    new_text = new_text.translate(translator)\n",
    "    \n",
    "    # Remove white spaces\n",
    "    new_text = \" \".join(new_text.split())\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    new_text = remove_stopwords(new_text)\n",
    "    \n",
    "    # Stemming\n",
    "    new_text = apply_stemming(new_text)\n",
    "    \n",
    "    # Apply filter with words room,hotel,stay\n",
    "    new_text = remove_by_filters(new_text,['room','hotel','stay'])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['cleaned'] = docs['text'].apply(lambda text: preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      night spring break call jr suit resembl wide h...\n",
       "1      fitzpatrick result glow review tripadvisor avo...\n",
       "2      book last minut vacat plan littl shop nightlif...\n",
       "3      shamblesfurnitur liter fall apart staff rude u...\n",
       "4      beauti wonder staff bottom line imposs sleep n...\n",
       "                             ...                        \n",
       "395    husband plan st year wed anniversari want go b...\n",
       "396    recent talbott night could disappoint terribl ...\n",
       "397    id expect luxuri pay attent detail realli hadn...\n",
       "398    select talbott recent famili vacat chicago cho...\n",
       "399    talbott claim chicago premier small luxuri exp...\n",
       "Name: cleaned, Length: 800, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification for All CLASSES\n",
    "### Naivebayes Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blanket</th>\n",
       "      <td>0.308833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra</th>\n",
       "      <td>0.224928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer</th>\n",
       "      <td>0.211808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fill</th>\n",
       "      <td>0.200712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manag</th>\n",
       "      <td>0.185219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fond</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folk</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5483 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfidf\n",
       "blanket  0.308833\n",
       "extra    0.224928\n",
       "beer     0.211808\n",
       "fill     0.200712\n",
       "manag    0.185219\n",
       "...           ...\n",
       "food     0.000000\n",
       "fond     0.000000\n",
       "follow   0.000000\n",
       "folk     0.000000\n",
       "zoo      0.000000\n",
       "\n",
       "[5483 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "doc_vectors=tfidf_vectorizer.fit_transform(docs.cleaned)\n",
    "sample_tfidf_vector = doc_vectors[40]\n",
    "df = pd.DataFrame(sample_tfidf_vector.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = MultinomialNB().fit(doc_vectors, docs.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same operations with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pipeline,k):\n",
    "    # Divide the data; test&training\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(docs.cleaned,docs.type,test_size=0.2,random_state=0)\n",
    "    # Instead of use %20 of data as a test, I will use K-Cross Validation\n",
    "    kfold = KFold(n_splits=k,shuffle=True,random_state=0)\n",
    "    k_cross_splits = kfold.split(docs.cleaned,docs.type)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in k_cross_splits:\n",
    "        X = docs['cleaned']\n",
    "        X = np.array(X)\n",
    "        y = docs['type']\n",
    "        y = np.array(y)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        pipeline.fit(X_train,y_train)\n",
    "        predicted = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test,predicted)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "        print(\"Accuracy Score:\",accuracy)\n",
    "        print(\"Classification Report\\n\",classification_report(y_test,predicted))\n",
    "        print(\"Confusion Matrix\\n\",confusion_matrix(y_test,predicted))\n",
    "        print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"Average accuracy of 5-cross validation:\",np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Unigram NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.825\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.78      0.95      0.86        88\n",
      "real_negative       0.92      0.67      0.77        72\n",
      "\n",
      "     accuracy                           0.82       160\n",
      "    macro avg       0.85      0.81      0.82       160\n",
      " weighted avg       0.84      0.82      0.82       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[84  4]\n",
      " [24 48]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.78125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.96      0.80        72\n",
      "real_negative       0.95      0.64      0.76        88\n",
      "\n",
      "     accuracy                           0.78       160\n",
      "    macro avg       0.82      0.80      0.78       160\n",
      " weighted avg       0.83      0.78      0.78       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[69  3]\n",
      " [32 56]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.79      0.98      0.87        83\n",
      "real_negative       0.96      0.71      0.82        77\n",
      "\n",
      "     accuracy                           0.85       160\n",
      "    macro avg       0.88      0.85      0.85       160\n",
      " weighted avg       0.87      0.85      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[81  2]\n",
      " [22 55]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.79      0.96      0.87        83\n",
      "real_negative       0.95      0.73      0.82        77\n",
      "\n",
      "     accuracy                           0.85       160\n",
      "    macro avg       0.87      0.85      0.85       160\n",
      " weighted avg       0.87      0.85      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[80  3]\n",
      " [21 56]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.725\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.63      0.97      0.77        74\n",
      "real_negative       0.96      0.51      0.67        86\n",
      "\n",
      "     accuracy                           0.73       160\n",
      "    macro avg       0.79      0.74      0.72       160\n",
      " weighted avg       0.81      0.72      0.71       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[72  2]\n",
      " [42 44]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.80625\n"
     ]
    }
   ],
   "source": [
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Naivebayes | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.85625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.82      0.94      0.88        88\n",
      "real_negative       0.92      0.75      0.82        72\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.87      0.85      0.85       160\n",
      " weighted avg       0.86      0.86      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[83  5]\n",
      " [18 54]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.99      0.81        72\n",
      "real_negative       0.98      0.62      0.76        88\n",
      "\n",
      "     accuracy                           0.79       160\n",
      "    macro avg       0.83      0.81      0.79       160\n",
      " weighted avg       0.85      0.79      0.78       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71  1]\n",
      " [33 55]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.86875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.80      0.99      0.89        83\n",
      "real_negative       0.98      0.74      0.84        77\n",
      "\n",
      "     accuracy                           0.87       160\n",
      "    macro avg       0.89      0.86      0.87       160\n",
      " weighted avg       0.89      0.87      0.87       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[82  1]\n",
      " [20 57]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.81      0.94      0.87        83\n",
      "real_negative       0.92      0.77      0.84        77\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.87      0.85      0.85       160\n",
      " weighted avg       0.87      0.86      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[78  5]\n",
      " [18 59]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.65      0.96      0.77        74\n",
      "real_negative       0.94      0.55      0.69        86\n",
      "\n",
      "     accuracy                           0.74       160\n",
      "    macro avg       0.79      0.75      0.73       160\n",
      " weighted avg       0.80      0.74      0.73       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71  3]\n",
      " [39 47]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.8212499999999998\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "\n",
    "# Build the model\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Naivebayes | Unigram-Bigram-Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.85      0.93      0.89        88\n",
      "real_negative       0.91      0.81      0.85        72\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.88      0.87      0.87       160\n",
      " weighted avg       0.88      0.88      0.87       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[82  6]\n",
      " [14 58]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.70      0.99      0.82        72\n",
      "real_negative       0.98      0.65      0.78        88\n",
      "\n",
      "     accuracy                           0.80       160\n",
      "    macro avg       0.84      0.82      0.80       160\n",
      " weighted avg       0.85      0.80      0.80       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71  1]\n",
      " [31 57]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.81      0.96      0.88        83\n",
      "real_negative       0.95      0.75      0.84        77\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.88      0.86      0.86       160\n",
      " weighted avg       0.88      0.86      0.86       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[80  3]\n",
      " [19 58]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.82      0.94      0.88        83\n",
      "real_negative       0.92      0.78      0.85        77\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.87      0.86      0.86       160\n",
      " weighted avg       0.87      0.86      0.86       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[78  5]\n",
      " [17 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.73125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.64      0.96      0.77        74\n",
      "real_negative       0.94      0.53      0.68        86\n",
      "\n",
      "     accuracy                           0.73       160\n",
      "    macro avg       0.79      0.75      0.72       160\n",
      " weighted avg       0.80      0.73      0.72       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71  3]\n",
      " [40 46]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.8262500000000002\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Decision Tree with criteria Entropy | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.66875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.72      0.66      0.69        88\n",
      "real_negative       0.62      0.68      0.65        72\n",
      "\n",
      "     accuracy                           0.67       160\n",
      "    macro avg       0.67      0.67      0.67       160\n",
      " weighted avg       0.67      0.67      0.67       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[58 30]\n",
      " [23 49]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.6875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.67      0.60      0.63        72\n",
      "real_negative       0.70      0.76      0.73        88\n",
      "\n",
      "     accuracy                           0.69       160\n",
      "    macro avg       0.68      0.68      0.68       160\n",
      " weighted avg       0.69      0.69      0.69       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[43 29]\n",
      " [21 67]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.74375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.76      0.73      0.75        83\n",
      "real_negative       0.72      0.75      0.74        77\n",
      "\n",
      "     accuracy                           0.74       160\n",
      "    macro avg       0.74      0.74      0.74       160\n",
      " weighted avg       0.74      0.74      0.74       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[61 22]\n",
      " [19 58]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.675\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.71      0.69        83\n",
      "real_negative       0.67      0.64      0.65        77\n",
      "\n",
      "     accuracy                           0.68       160\n",
      "    macro avg       0.67      0.67      0.67       160\n",
      " weighted avg       0.67      0.68      0.67       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[59 24]\n",
      " [28 49]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.68125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.63      0.77      0.69        74\n",
      "real_negative       0.75      0.60      0.67        86\n",
      "\n",
      "     accuracy                           0.68       160\n",
      "    macro avg       0.69      0.69      0.68       160\n",
      " weighted avg       0.69      0.68      0.68       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[57 17]\n",
      " [34 52]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.69125\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', decision_tree_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Decision Tree with criteria Gini | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.69      0.62      0.65        88\n",
      "real_negative       0.59      0.65      0.62        72\n",
      "\n",
      "     accuracy                           0.64       160\n",
      "    macro avg       0.64      0.64      0.64       160\n",
      " weighted avg       0.64      0.64      0.64       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[55 33]\n",
      " [25 47]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.67      0.65      0.66        72\n",
      "real_negative       0.72      0.74      0.73        88\n",
      "\n",
      "     accuracy                           0.70       160\n",
      "    macro avg       0.70      0.70      0.70       160\n",
      " weighted avg       0.70      0.70      0.70       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[47 25]\n",
      " [23 65]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.68125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.69      0.70      0.69        83\n",
      "real_negative       0.67      0.66      0.67        77\n",
      "\n",
      "     accuracy                           0.68       160\n",
      "    macro avg       0.68      0.68      0.68       160\n",
      " weighted avg       0.68      0.68      0.68       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[58 25]\n",
      " [26 51]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.68125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.72      0.70        83\n",
      "real_negative       0.68      0.64      0.66        77\n",
      "\n",
      "     accuracy                           0.68       160\n",
      "    macro avg       0.68      0.68      0.68       160\n",
      " weighted avg       0.68      0.68      0.68       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[60 23]\n",
      " [28 49]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.6875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.65      0.72      0.68        74\n",
      "real_negative       0.73      0.66      0.70        86\n",
      "\n",
      "     accuracy                           0.69       160\n",
      "    macro avg       0.69      0.69      0.69       160\n",
      " weighted avg       0.69      0.69      0.69       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[53 21]\n",
      " [29 57]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.6775\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"gini\")\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', decision_tree_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with K-NN | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.75\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.74      0.84      0.79        88\n",
      "real_negative       0.77      0.64      0.70        72\n",
      "\n",
      "     accuracy                           0.75       160\n",
      "    macro avg       0.75      0.74      0.74       160\n",
      " weighted avg       0.75      0.75      0.75       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74 14]\n",
      " [26 46]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.73125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.67      0.79      0.73        72\n",
      "real_negative       0.80      0.68      0.74        88\n",
      "\n",
      "     accuracy                           0.73       160\n",
      "    macro avg       0.74      0.74      0.73       160\n",
      " weighted avg       0.74      0.73      0.73       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[57 15]\n",
      " [28 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.70625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.82      0.74        83\n",
      "real_negative       0.75      0.58      0.66        77\n",
      "\n",
      "     accuracy                           0.71       160\n",
      "    macro avg       0.72      0.70      0.70       160\n",
      " weighted avg       0.71      0.71      0.70       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[68 15]\n",
      " [32 45]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.71875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.87      0.76        83\n",
      "real_negative       0.80      0.56      0.66        77\n",
      "\n",
      "     accuracy                           0.72       160\n",
      "    macro avg       0.74      0.71      0.71       160\n",
      " weighted avg       0.74      0.72      0.71       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[72 11]\n",
      " [34 43]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.71875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.67      0.78      0.72        74\n",
      "real_negative       0.78      0.66      0.72        86\n",
      "\n",
      "     accuracy                           0.72       160\n",
      "    macro avg       0.72      0.72      0.72       160\n",
      " weighted avg       0.73      0.72      0.72       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[58 16]\n",
      " [29 57]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.725\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "neigh_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', neigh_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with K-NN | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.80625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.79      0.88      0.83        88\n",
      "real_negative       0.83      0.72      0.77        72\n",
      "\n",
      "     accuracy                           0.81       160\n",
      "    macro avg       0.81      0.80      0.80       160\n",
      " weighted avg       0.81      0.81      0.80       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[77 11]\n",
      " [20 52]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.79375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.73      0.86      0.79        72\n",
      "real_negative       0.87      0.74      0.80        88\n",
      "\n",
      "     accuracy                           0.79       160\n",
      "    macro avg       0.80      0.80      0.79       160\n",
      " weighted avg       0.80      0.79      0.79       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[62 10]\n",
      " [23 65]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.73125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.69      0.89      0.77        83\n",
      "real_negative       0.83      0.56      0.67        77\n",
      "\n",
      "     accuracy                           0.73       160\n",
      "    macro avg       0.76      0.73      0.72       160\n",
      " weighted avg       0.75      0.73      0.72       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[74  9]\n",
      " [34 43]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.78125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.76      0.86      0.80        83\n",
      "real_negative       0.82      0.70      0.76        77\n",
      "\n",
      "     accuracy                           0.78       160\n",
      "    macro avg       0.79      0.78      0.78       160\n",
      " weighted avg       0.79      0.78      0.78       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71 12]\n",
      " [23 54]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.73125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.66      0.85      0.75        74\n",
      "real_negative       0.83      0.63      0.72        86\n",
      "\n",
      "     accuracy                           0.73       160\n",
      "    macro avg       0.75      0.74      0.73       160\n",
      " weighted avg       0.75      0.73      0.73       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[63 11]\n",
      " [32 54]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.76875\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "neigh_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', neigh_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SVM | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.84375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.88      0.83      0.85        88\n",
      "real_negative       0.81      0.86      0.83        72\n",
      "\n",
      "     accuracy                           0.84       160\n",
      "    macro avg       0.84      0.85      0.84       160\n",
      " weighted avg       0.85      0.84      0.84       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[73 15]\n",
      " [10 62]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.9125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.94      0.86      0.90        72\n",
      "real_negative       0.89      0.95      0.92        88\n",
      "\n",
      "     accuracy                           0.91       160\n",
      "    macro avg       0.92      0.91      0.91       160\n",
      " weighted avg       0.91      0.91      0.91       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[62 10]\n",
      " [ 4 84]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.88      0.90      0.89        83\n",
      "real_negative       0.89      0.87      0.88        77\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.89      0.89      0.89       160\n",
      " weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[75  8]\n",
      " [10 67]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.87      0.86      0.86        83\n",
      "real_negative       0.85      0.86      0.85        77\n",
      "\n",
      "     accuracy                           0.86       160\n",
      "    macro avg       0.86      0.86      0.86       160\n",
      " weighted avg       0.86      0.86      0.86       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[71 12]\n",
      " [11 66]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.86      0.88      0.87        74\n",
      "real_negative       0.89      0.87      0.88        86\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.87      0.88      0.87       160\n",
      " weighted avg       0.88      0.88      0.88       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[65  9]\n",
      " [11 75]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.875\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "svm_classifier = svm.SVC()\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', svm_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SVM | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.84375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.84      0.89      0.86        88\n",
      "real_negative       0.85      0.79      0.82        72\n",
      "\n",
      "     accuracy                           0.84       160\n",
      "    macro avg       0.84      0.84      0.84       160\n",
      " weighted avg       0.84      0.84      0.84       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[78 10]\n",
      " [15 57]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.84      0.93      0.88        72\n",
      "real_negative       0.94      0.85      0.89        88\n",
      "\n",
      "     accuracy                           0.89       160\n",
      "    macro avg       0.89      0.89      0.89       160\n",
      " weighted avg       0.89      0.89      0.89       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[67  5]\n",
      " [13 75]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.82      0.96      0.89        83\n",
      "real_negative       0.95      0.78      0.86        77\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.89      0.87      0.87       160\n",
      " weighted avg       0.89      0.88      0.87       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[80  3]\n",
      " [17 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.85      0.92      0.88        83\n",
      "real_negative       0.90      0.83      0.86        77\n",
      "\n",
      "     accuracy                           0.88       160\n",
      "    macro avg       0.88      0.87      0.87       160\n",
      " weighted avg       0.88      0.88      0.87       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[76  7]\n",
      " [13 64]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.85\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.78      0.93      0.85        74\n",
      "real_negative       0.93      0.78      0.85        86\n",
      "\n",
      "     accuracy                           0.85       160\n",
      "    macro avg       0.86      0.86      0.85       160\n",
      " weighted avg       0.86      0.85      0.85       160\n",
      "\n",
      "Confusion Matrix\n",
      " [[69  5]\n",
      " [19 67]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.86625\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "svm_classifier = svm.SVC()\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', svm_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
