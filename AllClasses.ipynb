{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Kaan-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kaan-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>I was completely blown away by this hotel. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>We've just returned from a two night stay at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>Excellent location, feels like a boutique hote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>I travel a lot for business and quite frankly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>real_positive</td>\n",
       "      <td>We visited for my 40th birthday. We had never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>My husband and I were planning our 1st year we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>I recently stayed at The Talbott Hotel for 3 n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>I'd expect a \"luxury\" hotel to pay more attent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>I selected The Talbott for my recent family va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>fake_negative</td>\n",
       "      <td>The Talbott Hotel claims to be Chicago's Premi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              type                                               text\n",
       "0    real_positive  I was completely blown away by this hotel. It ...\n",
       "1    real_positive  We've just returned from a two night stay at t...\n",
       "2    real_positive  Excellent location, feels like a boutique hote...\n",
       "3    real_positive  I travel a lot for business and quite frankly,...\n",
       "4    real_positive  We visited for my 40th birthday. We had never ...\n",
       "..             ...                                                ...\n",
       "395  fake_negative  My husband and I were planning our 1st year we...\n",
       "396  fake_negative  I recently stayed at The Talbott Hotel for 3 n...\n",
       "397  fake_negative  I'd expect a \"luxury\" hotel to pay more attent...\n",
       "398  fake_negative  I selected The Talbott for my recent family va...\n",
       "399  fake_negative  The Talbott Hotel claims to be Chicago's Premi...\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_documents(doc_type,path):\n",
    "    files = path.iterdir()\n",
    "    document_arr = []\n",
    "\n",
    "    for index,file in enumerate(files, start=0):\n",
    "        reader = open(file,\"r\")\n",
    "        text = reader.read()\n",
    "        document_arr.append({'type':doc_type,'text':text})\n",
    "    return document_arr\n",
    "\n",
    "real_positive_path = Path('opinion_spam/positive/truthful')\n",
    "fake_positive_path = Path('opinion_spam/positive/deceptive')\n",
    "real_negative_path = Path('opinion_spam/negative/truthful')\n",
    "fake_negative_path = Path('opinion_spam/negative/deceptive')\n",
    "\n",
    "docs = pd.DataFrame()\n",
    "docs = docs.append(read_documents('real_positive',real_positive_path))\n",
    "docs = docs.append(read_documents('fake_positive',fake_positive_path))\n",
    "docs = docs.append(read_documents('real_negative',real_negative_path))\n",
    "docs = docs.append(read_documents('fake_negative',fake_negative_path))\n",
    "len(docs)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords (text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    new_text = ' '.join([x for x in text.split() if x not in stop_words])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming (text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    new_text = ' '.join([stemmer.stem(x) for x in text.split()])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_by_filters (text,filters=[]):\n",
    "        new_text = ' '.join([x for x in text.split() if x not in filters])\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text (text):\n",
    "    # Lower text\n",
    "    new_text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    new_text = re.sub(r'\\d+', '', new_text) \n",
    "    \n",
    "    # Remove punctuations\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    new_text = new_text.translate(translator)\n",
    "    \n",
    "    # Remove white spaces\n",
    "    new_text = \" \".join(new_text.split())\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    new_text = remove_stopwords(new_text)\n",
    "    \n",
    "    # Stemming\n",
    "    new_text = apply_stemming(new_text)\n",
    "    \n",
    "    # Apply filter with words room,hotel,stay\n",
    "    new_text = remove_by_filters(new_text,['room','hotel','stay'])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['cleaned'] = docs['text'].apply(lambda text: preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      complet blown away magnific got great deal hap...\n",
       "1      weve return two night affinia chicago visit de...\n",
       "2      excel locat feel like boutiqu right next neima...\n",
       "3      travel lot busi quit frank expect start reach ...\n",
       "4      visit th birthday never chicago sure found dea...\n",
       "                             ...                        \n",
       "395    husband plan st year wed anniversari want go b...\n",
       "396    recent talbott night could disappoint terribl ...\n",
       "397    id expect luxuri pay attent detail realli hadn...\n",
       "398    select talbott recent famili vacat chicago cho...\n",
       "399    talbott claim chicago premier small luxuri exp...\n",
       "Name: cleaned, Length: 1600, dtype: object"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification for All CLASSES\n",
    "### Naivebayes Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>street</th>\n",
       "      <td>0.273838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0.213356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corner</th>\n",
       "      <td>0.205221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unmatch</th>\n",
       "      <td>0.181897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revolv</th>\n",
       "      <td>0.181897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folio</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foldout</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>focus</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7093 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfidf\n",
       "street   0.273838\n",
       "state    0.213356\n",
       "corner   0.205221\n",
       "unmatch  0.181897\n",
       "revolv   0.181897\n",
       "...           ...\n",
       "folio    0.000000\n",
       "foldout  0.000000\n",
       "fold     0.000000\n",
       "focus    0.000000\n",
       "zoo      0.000000\n",
       "\n",
       "[7093 rows x 1 columns]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "doc_vectors=tfidf_vectorizer.fit_transform(docs.cleaned)\n",
    "sample_tfidf_vector = doc_vectors[40]\n",
    "df = pd.DataFrame(sample_tfidf_vector.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = MultinomialNB().fit(doc_vectors, docs.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same operations with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pipeline,k):\n",
    "    # Divide the data; test&training\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(docs.cleaned,docs.type,test_size=0.2,random_state=0)\n",
    "    # Instead of use %20 of data as a test, I will use K-Cross Validation\n",
    "    kfold = KFold(n_splits=k,shuffle=True,random_state=0)\n",
    "    k_cross_splits = kfold.split(docs.cleaned,docs.type)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in k_cross_splits:\n",
    "        X = docs['cleaned']\n",
    "        X = np.array(X)\n",
    "        y = docs['type']\n",
    "        y = np.array(y)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        pipeline.fit(X_train,y_train)\n",
    "        predicted = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test,predicted)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "        print(\"Accuracy Score:\",accuracy)\n",
    "        print(\"Classification Report\\n\",classification_report(y_test,predicted))\n",
    "        print(\"Confusion Matrix\\n\",confusion_matrix(y_test,predicted))\n",
    "        print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"Average accuracy of 5-cross validation:\",np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Unigram NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.809375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.77      0.93      0.84        82\n",
      "fake_positive       0.82      0.87      0.84        83\n",
      "real_negative       0.88      0.65      0.75        75\n",
      "real_positive       0.81      0.78      0.79        80\n",
      "\n",
      "     accuracy                           0.81       320\n",
      "    macro avg       0.82      0.81      0.80       320\n",
      " weighted avg       0.82      0.81      0.81       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[76  2  3  1]\n",
      " [ 2 72  0  9]\n",
      " [20  1 49  5]\n",
      " [ 1 13  4 62]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.803125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.69      0.99      0.81        73\n",
      "fake_positive       0.93      0.82      0.87        94\n",
      "real_negative       0.92      0.57      0.70        83\n",
      "real_positive       0.74      0.87      0.80        70\n",
      "\n",
      "     accuracy                           0.80       320\n",
      "    macro avg       0.82      0.81      0.80       320\n",
      " weighted avg       0.83      0.80      0.80       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[72  1  0  0]\n",
      " [ 4 77  1 12]\n",
      " [27  0 47  9]\n",
      " [ 1  5  3 61]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.790625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.71      0.92      0.80        84\n",
      "fake_positive       0.75      0.95      0.84        66\n",
      "real_negative       0.86      0.61      0.71        79\n",
      "real_positive       0.92      0.71      0.80        91\n",
      "\n",
      "     accuracy                           0.79       320\n",
      "    macro avg       0.81      0.80      0.79       320\n",
      " weighted avg       0.81      0.79      0.79       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[77  4  3  0]\n",
      " [ 1 63  0  2]\n",
      " [27  0 48  4]\n",
      " [ 4 17  5 65]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.83125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.79      0.93      0.85        88\n",
      "fake_positive       0.83      0.91      0.87        82\n",
      "real_negative       0.96      0.65      0.78        77\n",
      "real_positive       0.80      0.81      0.80        73\n",
      "\n",
      "     accuracy                           0.83       320\n",
      "    macro avg       0.85      0.83      0.83       320\n",
      " weighted avg       0.84      0.83      0.83       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[82  2  1  3]\n",
      " [ 1 75  0  6]\n",
      " [20  1 50  6]\n",
      " [ 1 12  1 59]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.62      0.89      0.73        73\n",
      "fake_positive       0.72      0.92      0.81        75\n",
      "real_negative       0.84      0.50      0.63        86\n",
      "real_positive       0.87      0.69      0.77        86\n",
      "\n",
      "     accuracy                           0.74       320\n",
      "    macro avg       0.76      0.75      0.73       320\n",
      " weighted avg       0.77      0.74      0.73       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[65  3  4  1]\n",
      " [ 3 69  0  3]\n",
      " [37  1 43  5]\n",
      " [ 0 23  4 59]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.7943749999999999\n"
     ]
    }
   ],
   "source": [
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Naivebayes | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.821875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.79      0.91      0.85        82\n",
      "fake_positive       0.82      0.90      0.86        83\n",
      "real_negative       0.88      0.68      0.77        75\n",
      "real_positive       0.83      0.78      0.80        80\n",
      "\n",
      "     accuracy                           0.82       320\n",
      "    macro avg       0.83      0.82      0.82       320\n",
      " weighted avg       0.83      0.82      0.82       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[75  2  4  1]\n",
      " [ 2 75  0  6]\n",
      " [17  1 51  6]\n",
      " [ 1 14  3 62]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.778125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.66      0.99      0.79        73\n",
      "fake_positive       0.95      0.77      0.85        94\n",
      "real_negative       0.90      0.52      0.66        83\n",
      "real_positive       0.71      0.89      0.79        70\n",
      "\n",
      "     accuracy                           0.78       320\n",
      "    macro avg       0.80      0.79      0.77       320\n",
      " weighted avg       0.82      0.78      0.77       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[72  1  0  0]\n",
      " [ 6 72  0 16]\n",
      " [31  0 43  9]\n",
      " [ 0  3  5 62]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.75      0.92      0.82        84\n",
      "fake_positive       0.71      0.98      0.82        66\n",
      "real_negative       0.87      0.68      0.77        79\n",
      "real_positive       0.95      0.66      0.78        91\n",
      "\n",
      "     accuracy                           0.80       320\n",
      "    macro avg       0.82      0.81      0.80       320\n",
      " weighted avg       0.83      0.80      0.80       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[77  5  2  0]\n",
      " [ 1 65  0  0]\n",
      " [22  0 54  3]\n",
      " [ 3 22  6 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.821875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.80      0.93      0.86        88\n",
      "fake_positive       0.86      0.88      0.87        82\n",
      "real_negative       0.88      0.65      0.75        77\n",
      "real_positive       0.78      0.81      0.79        73\n",
      "\n",
      "     accuracy                           0.82       320\n",
      "    macro avg       0.83      0.82      0.82       320\n",
      " weighted avg       0.83      0.82      0.82       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[82  1  2  3]\n",
      " [ 0 72  2  8]\n",
      " [20  1 50  6]\n",
      " [ 1 10  3 59]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.759375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.63      0.92      0.74        73\n",
      "fake_positive       0.75      0.95      0.84        75\n",
      "real_negative       0.87      0.52      0.65        86\n",
      "real_positive       0.91      0.70      0.79        86\n",
      "\n",
      "     accuracy                           0.76       320\n",
      "    macro avg       0.79      0.77      0.76       320\n",
      " weighted avg       0.79      0.76      0.75       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[67  2  3  1]\n",
      " [ 2 71  0  2]\n",
      " [37  1 45  3]\n",
      " [ 1 21  4 60]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.79625\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "\n",
    "# Build the model\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Naivebayes | Unigram-Bigram-Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.815625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.80      0.91      0.85        82\n",
      "fake_positive       0.80      0.88      0.84        83\n",
      "real_negative       0.87      0.71      0.78        75\n",
      "real_positive       0.81      0.75      0.78        80\n",
      "\n",
      "     accuracy                           0.82       320\n",
      "    macro avg       0.82      0.81      0.81       320\n",
      " weighted avg       0.82      0.82      0.81       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[75  2  4  1]\n",
      " [ 3 73  0  7]\n",
      " [15  1 53  6]\n",
      " [ 1 15  4 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.7625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.65      0.97      0.78        73\n",
      "fake_positive       0.93      0.74      0.83        94\n",
      "real_negative       0.88      0.52      0.65        83\n",
      "real_positive       0.70      0.86      0.77        70\n",
      "\n",
      "     accuracy                           0.76       320\n",
      "    macro avg       0.79      0.77      0.76       320\n",
      " weighted avg       0.80      0.76      0.76       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[71  1  1  0]\n",
      " [ 7 70  0 17]\n",
      " [31  0 43  9]\n",
      " [ 1  4  5 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.790625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.76      0.90      0.83        84\n",
      "fake_positive       0.71      0.98      0.82        66\n",
      "real_negative       0.81      0.70      0.75        79\n",
      "real_positive       0.95      0.63      0.75        91\n",
      "\n",
      "     accuracy                           0.79       320\n",
      "    macro avg       0.81      0.80      0.79       320\n",
      " weighted avg       0.82      0.79      0.79       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[76  5  3  0]\n",
      " [ 1 65  0  0]\n",
      " [21  0 55  3]\n",
      " [ 2 22 10 57]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.83125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.81      0.92      0.86        88\n",
      "fake_positive       0.87      0.89      0.88        82\n",
      "real_negative       0.87      0.68      0.76        77\n",
      "real_positive       0.79      0.82      0.81        73\n",
      "\n",
      "     accuracy                           0.83       320\n",
      "    macro avg       0.83      0.83      0.83       320\n",
      " weighted avg       0.83      0.83      0.83       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[81  1  3  3]\n",
      " [ 0 73  2  7]\n",
      " [18  1 52  6]\n",
      " [ 1  9  3 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.753125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.64      0.93      0.76        73\n",
      "fake_positive       0.73      0.95      0.83        75\n",
      "real_negative       0.84      0.56      0.67        86\n",
      "real_positive       0.92      0.63      0.74        86\n",
      "\n",
      "     accuracy                           0.75       320\n",
      "    macro avg       0.78      0.77      0.75       320\n",
      " weighted avg       0.79      0.75      0.75       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[68  2  3  0]\n",
      " [ 2 71  0  2]\n",
      " [34  1 48  3]\n",
      " [ 3 23  6 54]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.790625\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', MultinomialNB()),  # Give TF-IDF representation to Naive Bayes\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Decision Tree with criteria Entropy | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.56875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.60      0.63      0.62        82\n",
      "fake_positive       0.63      0.73      0.68        83\n",
      "real_negative       0.52      0.40      0.45        75\n",
      "real_positive       0.50      0.49      0.49        80\n",
      "\n",
      "     accuracy                           0.57       320\n",
      "    macro avg       0.56      0.56      0.56       320\n",
      " weighted avg       0.56      0.57      0.56       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[52 10 16  4]\n",
      " [ 6 61  2 14]\n",
      " [21  3 30 21]\n",
      " [ 8 23 10 39]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.50625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.55      0.63      0.59        73\n",
      "fake_positive       0.61      0.48      0.54        94\n",
      "real_negative       0.51      0.48      0.49        83\n",
      "real_positive       0.37      0.44      0.40        70\n",
      "\n",
      "     accuracy                           0.51       320\n",
      "    macro avg       0.51      0.51      0.51       320\n",
      " weighted avg       0.52      0.51      0.51       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[46  7 10 10]\n",
      " [ 7 45 13 29]\n",
      " [22  7 40 14]\n",
      " [ 8 15 16 31]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.528125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.62      0.54      0.57        84\n",
      "fake_positive       0.42      0.58      0.48        66\n",
      "real_negative       0.56      0.56      0.56        79\n",
      "real_positive       0.55      0.46      0.50        91\n",
      "\n",
      "     accuracy                           0.53       320\n",
      "    macro avg       0.53      0.53      0.53       320\n",
      " weighted avg       0.54      0.53      0.53       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[45 14 15 10]\n",
      " [ 8 38  5 15]\n",
      " [16  9 44 10]\n",
      " [ 4 30 15 42]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.528125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.55      0.60        88\n",
      "fake_positive       0.52      0.55      0.53        82\n",
      "real_negative       0.49      0.58      0.53        77\n",
      "real_positive       0.44      0.42      0.43        73\n",
      "\n",
      "     accuracy                           0.53       320\n",
      "    macro avg       0.53      0.53      0.53       320\n",
      " weighted avg       0.54      0.53      0.53       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[48 12 22  6]\n",
      " [ 9 45  9 19]\n",
      " [11  7 45 14]\n",
      " [ 3 23 16 31]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.540625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.56      0.62      0.58        73\n",
      "fake_positive       0.50      0.59      0.54        75\n",
      "real_negative       0.60      0.51      0.55        86\n",
      "real_positive       0.51      0.47      0.49        86\n",
      "\n",
      "     accuracy                           0.54       320\n",
      "    macro avg       0.54      0.54      0.54       320\n",
      " weighted avg       0.54      0.54      0.54       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[45 12 13  3]\n",
      " [ 4 44  6 21]\n",
      " [21  7 44 14]\n",
      " [11 25 10 40]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.5343749999999999\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', decision_tree_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with Decision Tree with criteria Gini | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.4625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.54      0.44      0.48        82\n",
      "fake_positive       0.51      0.58      0.54        83\n",
      "real_negative       0.39      0.33      0.36        75\n",
      "real_positive       0.41      0.49      0.45        80\n",
      "\n",
      "     accuracy                           0.46       320\n",
      "    macro avg       0.46      0.46      0.46       320\n",
      " weighted avg       0.46      0.46      0.46       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[36 12 24 10]\n",
      " [ 5 48  9 21]\n",
      " [17  8 25 25]\n",
      " [ 9 26  6 39]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.48125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.46      0.52      0.49        73\n",
      "fake_positive       0.60      0.53      0.56        94\n",
      "real_negative       0.50      0.48      0.49        83\n",
      "real_positive       0.35      0.37      0.36        70\n",
      "\n",
      "     accuracy                           0.48       320\n",
      "    macro avg       0.48      0.48      0.48       320\n",
      " weighted avg       0.49      0.48      0.48       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[38 10 15 10]\n",
      " [15 50  9 20]\n",
      " [23  2 40 18]\n",
      " [ 7 21 16 26]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.49375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.57      0.46      0.51        84\n",
      "fake_positive       0.45      0.59      0.51        66\n",
      "real_negative       0.49      0.51      0.50        79\n",
      "real_positive       0.48      0.44      0.46        91\n",
      "\n",
      "     accuracy                           0.49       320\n",
      "    macro avg       0.50      0.50      0.49       320\n",
      " weighted avg       0.50      0.49      0.49       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[39 16 21  8]\n",
      " [ 5 39  6 16]\n",
      " [15  5 40 19]\n",
      " [ 9 27 15 40]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.496875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.57      0.53      0.55        88\n",
      "fake_positive       0.49      0.50      0.49        82\n",
      "real_negative       0.50      0.53      0.52        77\n",
      "real_positive       0.42      0.41      0.42        73\n",
      "\n",
      "     accuracy                           0.50       320\n",
      "    macro avg       0.49      0.49      0.49       320\n",
      " weighted avg       0.50      0.50      0.50       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[47 10 24  7]\n",
      " [14 41  6 21]\n",
      " [15  8 41 13]\n",
      " [ 7 25 11 30]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.525\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.55      0.53      0.54        73\n",
      "fake_positive       0.53      0.64      0.58        75\n",
      "real_negative       0.54      0.51      0.53        86\n",
      "real_positive       0.48      0.43      0.45        86\n",
      "\n",
      "     accuracy                           0.53       320\n",
      "    macro avg       0.53      0.53      0.53       320\n",
      " weighted avg       0.52      0.53      0.52       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[39 11 15  8]\n",
      " [ 7 48  5 15]\n",
      " [17  8 44 17]\n",
      " [ 8 24 17 37]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.491875\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"gini\")\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', decision_tree_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with K-NN | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.60625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.58      0.77      0.66        82\n",
      "fake_positive       0.55      0.67      0.61        83\n",
      "real_negative       0.70      0.37      0.49        75\n",
      "real_positive       0.67      0.59      0.63        80\n",
      "\n",
      "     accuracy                           0.61       320\n",
      "    macro avg       0.63      0.60      0.60       320\n",
      " weighted avg       0.62      0.61      0.60       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[63  8 10  1]\n",
      " [15 56  0 12]\n",
      " [25 12 28 10]\n",
      " [ 6 25  2 47]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.64375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.50      0.68      0.57        73\n",
      "fake_positive       0.68      0.82      0.74        94\n",
      "real_negative       0.78      0.48      0.60        83\n",
      "real_positive       0.71      0.56      0.62        70\n",
      "\n",
      "     accuracy                           0.64       320\n",
      "    macro avg       0.67      0.64      0.63       320\n",
      " weighted avg       0.67      0.64      0.64       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[50 11 11  1]\n",
      " [12 77  0  5]\n",
      " [28  5 40 10]\n",
      " [11 20  0 39]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.61      0.76      0.68        84\n",
      "fake_positive       0.54      0.86      0.67        66\n",
      "real_negative       0.65      0.43      0.52        79\n",
      "real_positive       0.78      0.49      0.60        91\n",
      "\n",
      "     accuracy                           0.62       320\n",
      "    macro avg       0.65      0.64      0.62       320\n",
      " weighted avg       0.65      0.62      0.62       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[64 10 10  0]\n",
      " [ 3 57  0  6]\n",
      " [31  7 34  7]\n",
      " [ 7 31  8 45]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.56875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.55      0.69      0.62        88\n",
      "fake_positive       0.49      0.79      0.60        82\n",
      "real_negative       0.86      0.40      0.55        77\n",
      "real_positive       0.62      0.34      0.44        73\n",
      "\n",
      "     accuracy                           0.57       320\n",
      "    macro avg       0.63      0.56      0.55       320\n",
      " weighted avg       0.63      0.57      0.56       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[61 22  4  1]\n",
      " [ 8 65  0  9]\n",
      " [34  7 31  5]\n",
      " [ 7 40  1 25]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.571875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.52      0.77      0.62        73\n",
      "fake_positive       0.51      0.83      0.63        75\n",
      "real_negative       0.77      0.31      0.45        86\n",
      "real_positive       0.67      0.44      0.53        86\n",
      "\n",
      "     accuracy                           0.57       320\n",
      "    macro avg       0.62      0.59      0.56       320\n",
      " weighted avg       0.63      0.57      0.55       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[56 11  3  3]\n",
      " [ 7 62  1  5]\n",
      " [36 12 27 11]\n",
      " [ 8 36  4 38]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.603125\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "neigh_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', neigh_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with K-NN | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.659375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.68      0.72      0.70        82\n",
      "fake_positive       0.56      0.75      0.64        83\n",
      "real_negative       0.75      0.53      0.62        75\n",
      "real_positive       0.71      0.62      0.67        80\n",
      "\n",
      "     accuracy                           0.66       320\n",
      "    macro avg       0.68      0.66      0.66       320\n",
      " weighted avg       0.68      0.66      0.66       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[59 10 12  1]\n",
      " [11 62  0 10]\n",
      " [16 10 40  9]\n",
      " [ 1 28  1 50]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.578125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.48      0.63      0.54        73\n",
      "fake_positive       0.58      0.69      0.63        94\n",
      "real_negative       0.78      0.48      0.60        83\n",
      "real_positive       0.56      0.49      0.52        70\n",
      "\n",
      "     accuracy                           0.58       320\n",
      "    macro avg       0.60      0.57      0.57       320\n",
      " weighted avg       0.61      0.58      0.58       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[46 16  8  3]\n",
      " [17 65  0 12]\n",
      " [26  5 40 12]\n",
      " [ 7 26  3 34]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.590625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.58      0.68      0.62        84\n",
      "fake_positive       0.47      0.79      0.59        66\n",
      "real_negative       0.68      0.49      0.57        79\n",
      "real_positive       0.76      0.45      0.57        91\n",
      "\n",
      "     accuracy                           0.59       320\n",
      "    macro avg       0.62      0.60      0.59       320\n",
      " weighted avg       0.63      0.59      0.59       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[57 16 10  1]\n",
      " [ 8 52  1  5]\n",
      " [25  8 39  7]\n",
      " [ 9 34  7 41]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.60      0.72      0.65        88\n",
      "fake_positive       0.55      0.83      0.66        82\n",
      "real_negative       0.81      0.49      0.61        77\n",
      "real_positive       0.69      0.42      0.53        73\n",
      "\n",
      "     accuracy                           0.62       320\n",
      "    macro avg       0.66      0.62      0.61       320\n",
      " weighted avg       0.66      0.62      0.62       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[63 18  5  2]\n",
      " [ 9 68  1  4]\n",
      " [25  6 38  8]\n",
      " [ 8 31  3 31]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.596875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.52      0.67      0.59        73\n",
      "fake_positive       0.52      0.84      0.64        75\n",
      "real_negative       0.79      0.43      0.56        86\n",
      "real_positive       0.74      0.49      0.59        86\n",
      "\n",
      "     accuracy                           0.60       320\n",
      "    macro avg       0.64      0.61      0.59       320\n",
      " weighted avg       0.65      0.60      0.59       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[49 15  6  3]\n",
      " [ 6 63  0  6]\n",
      " [31 12 37  6]\n",
      " [ 8 32  4 42]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.61\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "neigh_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', neigh_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SVM | Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.81875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.93      0.78      0.85        82\n",
      "fake_positive       0.83      0.88      0.85        83\n",
      "real_negative       0.71      0.87      0.78        75\n",
      "real_positive       0.83      0.75      0.79        80\n",
      "\n",
      "     accuracy                           0.82       320\n",
      "    macro avg       0.83      0.82      0.82       320\n",
      " weighted avg       0.83      0.82      0.82       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[64  2 15  1]\n",
      " [ 0 73  3  7]\n",
      " [ 5  1 65  4]\n",
      " [ 0 12  8 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.853125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.87      0.90      0.89        73\n",
      "fake_positive       0.95      0.81      0.87        94\n",
      "real_negative       0.83      0.86      0.84        83\n",
      "real_positive       0.77      0.86      0.81        70\n",
      "\n",
      "     accuracy                           0.85       320\n",
      "    macro avg       0.85      0.86      0.85       320\n",
      " weighted avg       0.86      0.85      0.85       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[66  1  6  0]\n",
      " [ 3 76  2 13]\n",
      " [ 7  0 71  5]\n",
      " [ 0  3  7 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.81875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.81      0.83      0.82        84\n",
      "fake_positive       0.81      0.88      0.84        66\n",
      "real_negative       0.77      0.78      0.77        79\n",
      "real_positive       0.89      0.79      0.84        91\n",
      "\n",
      "     accuracy                           0.82       320\n",
      "    macro avg       0.82      0.82      0.82       320\n",
      " weighted avg       0.82      0.82      0.82       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[70  5  9  0]\n",
      " [ 2 58  1  5]\n",
      " [13  0 62  4]\n",
      " [ 1  9  9 72]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.8625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.89      0.82      0.85        88\n",
      "fake_positive       0.89      0.91      0.90        82\n",
      "real_negative       0.80      0.87      0.83        77\n",
      "real_positive       0.87      0.85      0.86        73\n",
      "\n",
      "     accuracy                           0.86       320\n",
      "    macro avg       0.86      0.86      0.86       320\n",
      " weighted avg       0.86      0.86      0.86       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[72  3 12  1]\n",
      " [ 0 75  2  5]\n",
      " [ 7  0 67  3]\n",
      " [ 2  6  3 62]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.78125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.77      0.74      0.76        73\n",
      "fake_positive       0.76      0.87      0.81        75\n",
      "real_negative       0.77      0.77      0.77        86\n",
      "real_positive       0.82      0.76      0.79        86\n",
      "\n",
      "     accuracy                           0.78       320\n",
      "    macro avg       0.78      0.78      0.78       320\n",
      " weighted avg       0.78      0.78      0.78       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[54  2 15  2]\n",
      " [ 2 65  0  8]\n",
      " [14  2 66  4]\n",
      " [ 0 16  5 65]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.826875\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "svm_classifier = svm.SVC()\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', svm_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SVM | Unigram-Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.809375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.89      0.85      0.87        82\n",
      "fake_positive       0.77      0.89      0.83        83\n",
      "real_negative       0.80      0.76      0.78        75\n",
      "real_positive       0.78      0.72      0.75        80\n",
      "\n",
      "     accuracy                           0.81       320\n",
      "    macro avg       0.81      0.81      0.81       320\n",
      " weighted avg       0.81      0.81      0.81       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[70  4  7  1]\n",
      " [ 0 74  2  7]\n",
      " [ 9  1 57  8]\n",
      " [ 0 17  5 58]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.81875\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.80      0.92      0.85        73\n",
      "fake_positive       0.89      0.78      0.83        94\n",
      "real_negative       0.85      0.76      0.80        83\n",
      "real_positive       0.74      0.84      0.79        70\n",
      "\n",
      "     accuracy                           0.82       320\n",
      "    macro avg       0.82      0.82      0.82       320\n",
      " weighted avg       0.83      0.82      0.82       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[67  3  3  0]\n",
      " [ 4 73  3 14]\n",
      " [13  0 63  7]\n",
      " [ 0  6  5 59]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.828125\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.81      0.87      0.84        84\n",
      "fake_positive       0.78      0.94      0.85        66\n",
      "real_negative       0.81      0.77      0.79        79\n",
      "real_positive       0.92      0.76      0.83        91\n",
      "\n",
      "     accuracy                           0.83       320\n",
      "    macro avg       0.83      0.83      0.83       320\n",
      " weighted avg       0.84      0.83      0.83       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[73  5  6  0]\n",
      " [ 1 62  1  2]\n",
      " [14  0 61  4]\n",
      " [ 2 13  7 69]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.840625\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.85      0.85      0.85        88\n",
      "fake_positive       0.86      0.91      0.89        82\n",
      "real_negative       0.82      0.77      0.79        77\n",
      "real_positive       0.82      0.82      0.82        73\n",
      "\n",
      "     accuracy                           0.84       320\n",
      "    macro avg       0.84      0.84      0.84       320\n",
      " weighted avg       0.84      0.84      0.84       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[75  3  8  2]\n",
      " [ 0 75  2  5]\n",
      " [12  0 59  6]\n",
      " [ 1  9  3 60]]\n",
      "---------------------------------------------------------------------\n",
      "Accuracy Score: 0.784375\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "fake_negative       0.73      0.86      0.79        73\n",
      "fake_positive       0.76      0.87      0.81        75\n",
      "real_negative       0.86      0.69      0.76        86\n",
      "real_positive       0.81      0.74      0.78        86\n",
      "\n",
      "     accuracy                           0.78       320\n",
      "    macro avg       0.79      0.79      0.78       320\n",
      " weighted avg       0.79      0.78      0.78       320\n",
      "\n",
      "Confusion Matrix\n",
      " [[63  4  4  2]\n",
      " [ 1 65  1  8]\n",
      " [21  1 59  5]\n",
      " [ 1 16  5 64]]\n",
      "---------------------------------------------------------------------\n",
      "Average accuracy of 5-cross validation: 0.8162499999999999\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "svm_classifier = svm.SVC()\n",
    "text_classifier = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer), # Tokenize and Transform TF-IDF representation\n",
    "    ('clf', svm_classifier),  # Give TF-IDF representation to Decision Tree\n",
    "])\n",
    "\n",
    "build_model(text_classifier,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
